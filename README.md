# Udacity-Sensor-Fusion-Nanodegree
In this program, I have learned knowledge in different sensors, Lidar, Camera and Radar. Code has been developed to detect obstacles using Lidar point cloud data, to track the object using Camera images, to detect range and velocity of targe based on Radar data, and to fuse Lidar/Radar measurement to predict the object's movement using Kalman Filter.




Sensor Fusion by combing Lidar's high resolution imaging with radar's ability to measure velocity of objects we can get a better understanding of the surrounding environment than we could using one of the sensors alone.

Project 1 - Lidar Obstacle Detection
In this project, I processed multiple point clouds data files from Lidar sensor, and detected the cars or other obstacles on a city street. The detection pipeline was implemented by the Voxel Grid and ROI based filtering, 3D RANSAC segmentation, Euclidean clustering based on KD-Tree, and bounding boxes.

My final result is shown below, where the green points represent the street surface and the obstacles are marked in the red boxes.

### Resources 
1. https://github.com/fanweng/Udacity-Sensor-Fusion-Nanodegree/tree/main
